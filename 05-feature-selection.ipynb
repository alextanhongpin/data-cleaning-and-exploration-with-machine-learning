{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03356463-9d4e-464d-baa1-ad5482e0aab2",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "We will explore the following topics:\n",
    "- selecting features for classification models\n",
    "- selecting features for regression models\n",
    "- using forward and backward feature selection\n",
    "- using exhaustive feature selection\n",
    "- eliminating features recursively in a regression model\n",
    "- eliminating features recursively in a classification model\n",
    "- using Boruta for feature selection\n",
    "- using regularization and other embedded methods\n",
    "- using principal component analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c59b70-e1dd-4a6a-b2ef-af45ae18d392",
   "metadata": {},
   "source": [
    "## Selecting features for classification models\n",
    "\n",
    "_Filter methods_ are techniques for determining the _k-best_ features based on their linear and non-linear relationship with the target. \n",
    "\n",
    "They are also someitmes called _univariante_ methods since they evaluate the relationship between the feature and the target independent of the impact of other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb46573-d0ec-444f-ad75-fb0416ead804",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mutual information classification for feature selection with a categorical target\n",
    "\n",
    "We can use __mutual information__ classification or __analysis of variance (ANOVA)__ tests to select features when we have a categorical target. \n",
    "\n",
    "__Mutual information__ is a measure of how much information about a variable is provided by knowing the value of another variable. At the extreme, when features are completely independent, the mutual information score is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4587b423-6fe8-4df9-b5d4-989d9b7f9d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from data.load import load_nls97compba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8bce2f-b231-406d-83a9-247ffdca9444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nls97compba = load_nls97compba()\n",
    "feature_cols = [\n",
    "    \"gender\",\n",
    "    \"satverbal\",\n",
    "    \"satmath\",\n",
    "    \"gpascience\",\n",
    "    \"gpaenglish\",\n",
    "    \"gpamath\",\n",
    "    \"gpaoverall\",\n",
    "    \"motherhighgrade\",\n",
    "    \"fatherhighgrade\",\n",
    "    \"parentincome\",\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    nls97compba[feature_cols],\n",
    "    nls97compba[[\"completedba\"]],\n",
    "    test_size=0.3,\n",
    "    random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad524572-958d-4a81-ad9c-71f460ef5e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop_last=True, variables=[\"gender\"])\n",
    "X_train_enc = ohe.fit_transform(X_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standcols = X_train_enc.iloc[:, :-1].columns\n",
    "X_train_enc = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train_enc[standcols]),\n",
    "    columns=standcols,\n",
    "    index=X_train_enc.index,\n",
    ").join(X_train_enc[[\"gender_Female\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dfa252-ff06-4ec5-acbf-da11a9a6477b",
   "metadata": {},
   "source": [
    "We are ready to select features for our model of bachelor's degree completion, using mutual information classification.\n",
    "\n",
    "We call `fit` and use the `get_support` method to get the five best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "017155ed-2da6-422b-a8ed-fba9c4a28671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satverbal', 'satmath', 'gpascience', 'gpaenglish', 'gpaoverall'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksel = SelectKBest(score_func=mutual_info_classif, k=5)\n",
    "ksel.fit(X_train_enc, y_train.values.ravel())\n",
    "\n",
    "sel_cols = X_train_enc.columns[ksel.get_support()]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837cc9b-95da-4ec6-ab74-473b90339b6f",
   "metadata": {},
   "source": [
    "We can see the score of each features using the `scores_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078d7601-c790-4b41-a923-b03d20faf26c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpaenglish</td>\n",
       "      <td>0.103650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpaoverall</td>\n",
       "      <td>0.095984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satmath</td>\n",
       "      <td>0.072620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satverbal</td>\n",
       "      <td>0.063807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpascience</td>\n",
       "      <td>0.044314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpamath</td>\n",
       "      <td>0.041551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>motherhighgrade</td>\n",
       "      <td>0.036985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>parentincome</td>\n",
       "      <td>0.031136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fatherhighgrade</td>\n",
       "      <td>0.021799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gender_Female</td>\n",
       "      <td>0.019019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature     score\n",
       "3       gpaenglish  0.103650\n",
       "5       gpaoverall  0.095984\n",
       "1          satmath  0.072620\n",
       "0        satverbal  0.063807\n",
       "2       gpascience  0.044314\n",
       "4          gpamath  0.041551\n",
       "6  motherhighgrade  0.036985\n",
       "8     parentincome  0.031136\n",
       "7  fatherhighgrade  0.021799\n",
       "9    gender_Female  0.019019"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\"score\": ksel.scores_, \"feature\": X_train_enc.columns},\n",
    "    columns=[\"feature\", \"score\"],\n",
    ").sort_values([\"score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08b8a10-8975-4786-92d5-55aac5ed75ec",
   "metadata": {},
   "source": [
    "^ This is a stochastic process, so we will get different results each time we run it.\n",
    "\n",
    "To get the same results each time, you can pass a partial function to `score_func`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52a1e241-1e24-45f4-a7d3-2d6c55f770c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "ksel = SelectKBest(score_func=partial(mutual_info_classif, random_state=0), k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4ca1f6-2367-481a-aa4b-3038d8d9752b",
   "metadata": {},
   "source": [
    "We can create a DataFrame with just the important features using the `sel_cols` array we created using the `get_support` (or use the `transform` method of `SelectKBest` instead, but it returns array instead of DataFrame). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44de5446-29be-4ad3-af02-d59887cf5907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satverbal     float64\n",
       "satmath       float64\n",
       "gpascience    float64\n",
       "gpaenglish    float64\n",
       "gpaoverall    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_analysis = X_train_enc[sel_cols]\n",
    "X_train_analysis.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f1974-8f7c-4aa4-90c9-5af9710d511e",
   "metadata": {},
   "source": [
    "### ANOVA F-value for feature selection with a categorical target\n",
    "\n",
    "Alternatively, we can use ANOVA instead of mutual information. ANOVA evaluates how different the mean for a feature is for each target class. This is a good metric for univariante feature selection when we can assume a _linear relationship_ between features and the target and our features are _normally distributed_. If those assumptions do not hold, __mutual information__ classification is a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c6d429d-7bbb-45a8-98ea-0fdea08189ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satverbal', 'satmath', 'gpascience', 'gpaenglish', 'gpaoverall'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksel = SelectKBest(score_func=f_classif, k=5)\n",
    "ksel.fit(X_train_enc, y_train.values.ravel())\n",
    "\n",
    "sel_cols = X_train_enc.columns[ksel.get_support()]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc52d693-c167-4ec4-95ce-36b4d6a2356e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpaoverall</td>\n",
       "      <td>119.471301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpaenglish</td>\n",
       "      <td>108.006221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpascience</td>\n",
       "      <td>96.823929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satmath</td>\n",
       "      <td>84.901228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satverbal</td>\n",
       "      <td>77.362692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpamath</td>\n",
       "      <td>60.929884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fatherhighgrade</td>\n",
       "      <td>37.480915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>motherhighgrade</td>\n",
       "      <td>29.377457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>parentincome</td>\n",
       "      <td>22.265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gender_Female</td>\n",
       "      <td>15.098132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature       score\n",
       "5       gpaoverall  119.471301\n",
       "3       gpaenglish  108.006221\n",
       "2       gpascience   96.823929\n",
       "1          satmath   84.901228\n",
       "0        satverbal   77.362692\n",
       "4          gpamath   60.929884\n",
       "7  fatherhighgrade   37.480915\n",
       "6  motherhighgrade   29.377457\n",
       "8     parentincome   22.265728\n",
       "9    gender_Female   15.098132"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\"score\": ksel.scores_, \"feature\": X_train_enc.columns},\n",
    "    columns=[\"feature\", \"score\"],\n",
    ").sort_values([\"score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d08d995-5940-442d-9cc4-2013a41fab44",
   "metadata": {},
   "source": [
    "^ Showing the scores gives us some indication of whether the selected value for _k_ makes best sense. \n",
    "\n",
    "There is a big decline from the sixth to seventh (61-37), suggesting that we should at least consider a value for _k_ of 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b90d9-7c7c-4e46-9e9d-3ac9a81f40a9",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "ANOVA tests, and the mutual information classification we did earlier, do not take into account features that are only important in multivariante analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b0b70e-3917-4985-b6dc-4b1205586223",
   "metadata": {},
   "source": [
    "## Selecting features for regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6337ea2-85af-48b2-a29b-9229012d7ad8",
   "metadata": {},
   "source": [
    "__Regression models__ have a continuous target. Two good options are selection based on F-tests and selection based on mutual information for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2860330-0a78-453c-9ae2-7afcbbf11565",
   "metadata": {},
   "source": [
    "### F-tests for feature selection with a continuous target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81abcfca-067d-4b86-96a2-d85d38bf2d99",
   "metadata": {},
   "source": [
    "The F-statistic is a measure of the strength of the linear correlation between a target and a single regressor (`f_regression` scoring function in `scikit-learn`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc4ab2f5-b8f4-47ef-b0d8-408ed626223c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from data.load import load_nls97wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb1469df-b2d6-4ab8-aafe-6d6fd6e944b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nls97wages = load_nls97wages()\n",
    "feature_cols = [\n",
    "    \"satverbal\",\n",
    "    \"satmath\",\n",
    "    \"gpascience\",\n",
    "    \"gpaenglish\",\n",
    "    \"gpamath\",\n",
    "    \"gpaoverall\",\n",
    "    \"gender\",\n",
    "    \"motherhighgrade\",\n",
    "    \"fatherhighgrade\",\n",
    "    \"parentincome\",\n",
    "    \"completedba\",\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    nls97wages[feature_cols],\n",
    "    nls97wages[[\"wageincome\"]],\n",
    "    test_size=0.3,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "cat_cols = [\"gender\"]\n",
    "num_cols = feature_cols[:]\n",
    "num_cols.remove(\"gender\")\n",
    "\n",
    "cat_transformer = make_pipeline(OneHotEncoder(drop=\"first\"))\n",
    "num_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", cat_transformer, cat_cols),\n",
    "        (\"num\", num_transformer, num_cols),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,  # We don't need to prefix every feature with cat_ and num_.\n",
    ")\n",
    "\n",
    "X_train_enc = pd.DataFrame(\n",
    "    transformer.fit_transform(X_train),\n",
    "    columns=transformer.get_feature_names_out(),\n",
    "    index=X_train.index,\n",
    ")\n",
    "y_train = pd.DataFrame(\n",
    "    scaler.fit_transform(y_train), columns=[\"wageincome\"], index=y_train.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f29e7aa-5a0d-4dd9-adfc-65cbc9e2680c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender_Male', 'satmath', 'gpascience', 'parentincome', 'completedba'], dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksel = SelectKBest(score_func=f_regression, k=5)\n",
    "ksel.fit(X_train_enc, y_train.values.ravel())\n",
    "sel_cols = X_train_enc.columns[ksel.get_support()]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e95ca85-6f55-4bb7-adf4-a5cc1e573b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>satmath</td>\n",
       "      <td>44.812092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>completedba</td>\n",
       "      <td>37.506374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender_Male</td>\n",
       "      <td>25.941412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>parentincome</td>\n",
       "      <td>24.374384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpascience</td>\n",
       "      <td>20.532561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satverbal</td>\n",
       "      <td>18.887186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpaoverall</td>\n",
       "      <td>17.292617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpamath</td>\n",
       "      <td>12.780981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpaenglish</td>\n",
       "      <td>10.126248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>motherhighgrade</td>\n",
       "      <td>9.171498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fatherhighgrade</td>\n",
       "      <td>8.222967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature      score\n",
       "2           satmath  44.812092\n",
       "10      completedba  37.506374\n",
       "0       gender_Male  25.941412\n",
       "9      parentincome  24.374384\n",
       "3        gpascience  20.532561\n",
       "1         satverbal  18.887186\n",
       "6        gpaoverall  17.292617\n",
       "5           gpamath  12.780981\n",
       "4        gpaenglish  10.126248\n",
       "7   motherhighgrade   9.171498\n",
       "8   fatherhighgrade   8.222967"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\"score\": ksel.scores_, \"feature\": X_train_enc.columns},\n",
    "    columns=[\"feature\", \"score\"],\n",
    ").sort_values([\"score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac56688-009b-4aff-a314-03b865c9f4e3",
   "metadata": {},
   "source": [
    "^ The disadvantage of the __F-statistic__ is that it assumes a linear relationship between each feature and the target. When that assumption does not make sense, we can use mutual information for regression instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d55d02-3db9-4473-b8a7-5f1fa61f8587",
   "metadata": {},
   "source": [
    "### Mutual information for feature selection with a continuous target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c82db3f-83ff-4be8-9e9d-23f3c9c090a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender_Male', 'satmath', 'gpascience', 'fatherhighgrade',\n",
       "       'completedba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "ksel = SelectKBest(partial(mutual_info_regression, random_state=0), k=5)\n",
    "ksel.fit(X_train_enc, y_train.values.ravel())\n",
    "\n",
    "sel_cols = X_train_enc.columns[ksel.get_support()]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e882cd85-ddb2-4cc7-b3aa-21a3628e1c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>satmath</td>\n",
       "      <td>0.099232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender_Male</td>\n",
       "      <td>0.064096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>completedba</td>\n",
       "      <td>0.059069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpascience</td>\n",
       "      <td>0.052042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fatherhighgrade</td>\n",
       "      <td>0.037278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>parentincome</td>\n",
       "      <td>0.014786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpamath</td>\n",
       "      <td>0.009263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satverbal</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpaenglish</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpaoverall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>motherhighgrade</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature     score\n",
       "2           satmath  0.099232\n",
       "0       gender_Male  0.064096\n",
       "10      completedba  0.059069\n",
       "3        gpascience  0.052042\n",
       "8   fatherhighgrade  0.037278\n",
       "9      parentincome  0.014786\n",
       "5           gpamath  0.009263\n",
       "1         satverbal  0.000000\n",
       "4        gpaenglish  0.000000\n",
       "6        gpaoverall  0.000000\n",
       "7   motherhighgrade  0.000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\"score\": ksel.scores_, \"feature\": X_train_enc.columns},\n",
    "    columns=[\"feature\", \"score\"],\n",
    ").sort_values([\"score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10c95b-8223-4cf2-addf-77719568f348",
   "metadata": {},
   "source": [
    "^ `parentincome` was selected with F-tests and `fatherhighgrade` with mutual information. Otherwise, the same features are selected.\n",
    "\n",
    "A key advantage of __mutual information__ for regression compared with __F-tests__ is that it does not assume a linear relationship between the feature and the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545afde-b39c-441d-a39b-94293b023a13",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "The feature selection methods we have used so far are known as _filter methods_. They examine the univariante relationship betwen each feature and the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb84c4a4-9416-46a7-9d4e-ead9fc3f4dc5",
   "metadata": {},
   "source": [
    "\n",
    "## Using forward and backward feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f09f9d-8f34-4ca1-863c-fc07390ca7df",
   "metadata": {},
   "source": [
    "__Forward__ and __backward__ feature selection, as their names suggest, select features by adding them one by one - or subtracting them for backward selection - and assessing the impact on model performance after each iteration. Since both methods assess that performance based on a given algorithm, they are considered __wrapper__ selection methods.\n",
    "\n",
    "\n",
    "Wrapper feature selection methods have two advantages over the filter method we have explored so far.\n",
    "\n",
    "- they evaluate the importance of features as other features are included\n",
    "- since features are evaluated based on their contributions to the performance of specific algorithm, we get a better sense of which features will ultimately matter\n",
    "\n",
    "The main disadvantage of wrapper methods is that they can be quite expensive computationally since they retrain the model after each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f746a64f-c931-45b3-a5b0-80c416ddf8f3",
   "metadata": {},
   "source": [
    "### Using forward feature selection\n",
    "\n",
    "__Forward feature selection__ starts by identifying a subset of features that individually have a significant relationship with a target, not unlike the filter methods.\n",
    "\n",
    "\n",
    "We can use forward feature selection to develop a model of bachelor's degree completion. Since wrapper method require us to choose an algorithm, and this is a binary target, let's use `scikit-learn`'s __random forest classifier__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3646db95-5235-4f66-a584-b0e148c41426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from data.load import load_nls97compba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19a506f8-53eb-49e9-955e-2f73152ebbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>satverbal</th>\n",
       "      <th>satmath</th>\n",
       "      <th>gpascience</th>\n",
       "      <th>gpaenglish</th>\n",
       "      <th>gpamath</th>\n",
       "      <th>gpaoverall</th>\n",
       "      <th>motherhighgrade</th>\n",
       "      <th>fatherhighgrade</th>\n",
       "      <th>parentincome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185424</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.211808</td>\n",
       "      <td>-0.936656</td>\n",
       "      <td>-1.501666</td>\n",
       "      <td>-1.290166</td>\n",
       "      <td>-0.824340</td>\n",
       "      <td>-1.054224</td>\n",
       "      <td>-0.777285</td>\n",
       "      <td>-0.884695</td>\n",
       "      <td>1.007125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.120269</td>\n",
       "      <td>-0.326391</td>\n",
       "      <td>1.085734</td>\n",
       "      <td>0.845885</td>\n",
       "      <td>1.339766</td>\n",
       "      <td>0.827237</td>\n",
       "      <td>0.742526</td>\n",
       "      <td>0.180973</td>\n",
       "      <td>-0.121043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834993</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.527432</td>\n",
       "      <td>0.981319</td>\n",
       "      <td>0.247060</td>\n",
       "      <td>0.311872</td>\n",
       "      <td>0.146325</td>\n",
       "      <td>-0.025984</td>\n",
       "      <td>0.742526</td>\n",
       "      <td>0.891418</td>\n",
       "      <td>-0.476950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379604</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.435893</td>\n",
       "      <td>0.719777</td>\n",
       "      <td>-0.912809</td>\n",
       "      <td>0.116068</td>\n",
       "      <td>0.464576</td>\n",
       "      <td>-0.485410</td>\n",
       "      <td>0.362573</td>\n",
       "      <td>0.891418</td>\n",
       "      <td>-0.491161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882321</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.754114</td>\n",
       "      <td>-0.675114</td>\n",
       "      <td>-0.127667</td>\n",
       "      <td>-0.364544</td>\n",
       "      <td>0.225888</td>\n",
       "      <td>0.455320</td>\n",
       "      <td>1.122479</td>\n",
       "      <td>-0.174250</td>\n",
       "      <td>0.821076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932713</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.351282</td>\n",
       "      <td>0.719777</td>\n",
       "      <td>0.693163</td>\n",
       "      <td>-0.400145</td>\n",
       "      <td>-0.203751</td>\n",
       "      <td>-0.091616</td>\n",
       "      <td>0.742526</td>\n",
       "      <td>-0.884695</td>\n",
       "      <td>1.007125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301273</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>-0.064849</td>\n",
       "      <td>-1.430289</td>\n",
       "      <td>-0.275542</td>\n",
       "      <td>-0.140101</td>\n",
       "      <td>-0.769817</td>\n",
       "      <td>-0.777285</td>\n",
       "      <td>-0.884695</td>\n",
       "      <td>-0.398136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739668</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.662575</td>\n",
       "      <td>-0.239211</td>\n",
       "      <td>-0.484550</td>\n",
       "      <td>-0.560348</td>\n",
       "      <td>-0.299226</td>\n",
       "      <td>-0.660430</td>\n",
       "      <td>0.362573</td>\n",
       "      <td>-0.174250</td>\n",
       "      <td>-0.556476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659296</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.218737</td>\n",
       "      <td>-1.023837</td>\n",
       "      <td>-1.430289</td>\n",
       "      <td>-1.290166</td>\n",
       "      <td>-0.537914</td>\n",
       "      <td>-0.660430</td>\n",
       "      <td>-0.397332</td>\n",
       "      <td>-0.884695</td>\n",
       "      <td>-0.613874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798449</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.435893</td>\n",
       "      <td>-0.675114</td>\n",
       "      <td>-1.037718</td>\n",
       "      <td>-0.489147</td>\n",
       "      <td>-0.156013</td>\n",
       "      <td>-1.229244</td>\n",
       "      <td>-0.397332</td>\n",
       "      <td>-0.529472</td>\n",
       "      <td>-0.174482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>634 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gender_Male  satverbal   satmath  gpascience  gpaenglish   gpamath  \\\n",
       "personid                                                                       \n",
       "185424            0.0  -1.211808 -0.936656   -1.501666   -1.290166 -0.824340   \n",
       "162597            0.0  -1.120269 -0.326391    1.085734    0.845885  1.339766   \n",
       "834993            1.0   0.527432  0.981319    0.247060    0.311872  0.146325   \n",
       "379604            1.0   0.435893  0.719777   -0.912809    0.116068  0.464576   \n",
       "882321            0.0  -0.754114 -0.675114   -0.127667   -0.364544  0.225888   \n",
       "...               ...        ...       ...         ...         ...       ...   \n",
       "932713            1.0   1.351282  0.719777    0.693163   -0.400145 -0.203751   \n",
       "301273            1.0   0.069737 -0.064849   -1.430289   -0.275542 -0.140101   \n",
       "739668            0.0  -0.662575 -0.239211   -0.484550   -0.560348 -0.299226   \n",
       "659296            1.0  -2.218737 -1.023837   -1.430289   -1.290166 -0.537914   \n",
       "798449            1.0   0.435893 -0.675114   -1.037718   -0.489147 -0.156013   \n",
       "\n",
       "          gpaoverall  motherhighgrade  fatherhighgrade  parentincome  \n",
       "personid                                                              \n",
       "185424     -1.054224        -0.777285        -0.884695      1.007125  \n",
       "162597      0.827237         0.742526         0.180973     -0.121043  \n",
       "834993     -0.025984         0.742526         0.891418     -0.476950  \n",
       "379604     -0.485410         0.362573         0.891418     -0.491161  \n",
       "882321      0.455320         1.122479        -0.174250      0.821076  \n",
       "...              ...              ...              ...           ...  \n",
       "932713     -0.091616         0.742526        -0.884695      1.007125  \n",
       "301273     -0.769817        -0.777285        -0.884695     -0.398136  \n",
       "739668     -0.660430         0.362573        -0.174250     -0.556476  \n",
       "659296     -0.660430        -0.397332        -0.884695     -0.613874  \n",
       "798449     -1.229244        -0.397332        -0.529472     -0.174482  \n",
       "\n",
       "[634 rows x 10 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nls97compba = load_nls97compba()\n",
    "\n",
    "feature_cols = [\n",
    "    \"gender\",\n",
    "    \"satverbal\",\n",
    "    \"satmath\",\n",
    "    \"gpascience\",\n",
    "    \"gpaenglish\",\n",
    "    \"gpamath\",\n",
    "    \"gpaoverall\",\n",
    "    \"motherhighgrade\",\n",
    "    \"fatherhighgrade\",\n",
    "    \"parentincome\",\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    nls97compba[feature_cols],\n",
    "    nls97compba[[\"completedba\"]],\n",
    "    test_size=0.3,\n",
    "    random_state=0,\n",
    ")\n",
    "cat_columns = [\"gender\"]\n",
    "num_columns = feature_cols[:]\n",
    "num_columns.remove(\"gender\")\n",
    "\n",
    "cat_transformer = make_pipeline(OneHotEncoder(drop=\"first\"))\n",
    "num_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    [(\"cat\", cat_transformer, cat_columns), (\"num\", num_transformer, num_columns)],\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "X_train_enc = pd.DataFrame(\n",
    "    transformer.fit_transform(X_train),\n",
    "    columns=transformer.get_feature_names_out(),\n",
    "    index=X_train.index,\n",
    ")\n",
    "X_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c918d10-4309-4ce9-9659-0454e35d1fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentialFeatureSelector(estimator=RandomForestClassifier(n_jobs=-1,\n",
       "                                                           random_state=0),\n",
       "                          n_features_to_select=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(estimator=RandomForestClassifier(n_jobs=-1,\n",
       "                                                           random_state=0),\n",
       "                          n_features_to_select=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentialFeatureSelector(estimator=RandomForestClassifier(n_jobs=-1,\n",
       "                                                           random_state=0),\n",
       "                          n_features_to_select=5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)\n",
    "sfs = SequentialFeatureSelector(rfc, n_features_to_select=5, direction=\"forward\", cv=5)\n",
    "sfs.fit(X_train_enc, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cf583afd-7e0c-40fc-8a7c-9ba580ce884c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender_Male', 'satmath', 'gpaenglish', 'gpaoverall',\n",
       "       'fatherhighgrade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_cols = X_train_enc.columns[sfs.get_support()]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946aafd2-69db-41d5-88ab-ed2d1057e957",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summary\n",
    "\n",
    "One disadvantage of forward selection si that _once a feature is selected, it is not removed, even though it may decline in importance as additional features are added_. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b137853-89bd-494c-80f2-2f068539c8ae",
   "metadata": {},
   "source": [
    "## Using backward feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6a37b-6284-497f-afb2-5a82e29d3338",
   "metadata": {},
   "source": [
    "Backward feature selection starts with all features and eliminates teh least important. It then repeats this process with the remaining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4fb962e-aba7-45d5-a716-3f525633f75a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentialFeatureSelector(direction=&#x27;backward&#x27;,\n",
       "                          estimator=RandomForestClassifier(n_jobs=-1,\n",
       "                                                           random_state=0),\n",
       "                          n_features_to_select=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(direction=&#x27;backward&#x27;,\n",
       "                          estimator=RandomForestClassifier(n_jobs=-1,\n",
       "                                                           random_state=0),\n",
       "                          n_features_to_select=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentialFeatureSelector(direction='backward',\n",
       "                          estimator=RandomForestClassifier(n_jobs=-1,\n",
       "                                                           random_state=0),\n",
       "                          n_features_to_select=5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)\n",
    "sfs = SequentialFeatureSelector(rfc, n_features_to_select=5, direction=\"backward\", cv=5)\n",
    "sfs.fit(X_train_enc, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecd77288-a45d-4fee-88a9-ba7ab0c73b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender_Male', 'satverbal', 'gpaoverall', 'fatherhighgrade',\n",
       "       'parentincome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_cols = X_train_enc.columns[sfs.get_support()]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548f708-58cb-4041-854c-ea91b5035ee5",
   "metadata": {},
   "source": [
    "^ We get different results for out feature selection. `satmath` and `gpaenglish` are no longer selected, and `gpaoverall` and `parentincome` are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7823f-3d84-4bfb-9cdf-501a0d5b7712",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Backward feature selection has the opposite drawback to forward feature selection. _Once a feature has been removed, it is not re-evaluated, even though its importance may change with different feature mixtures_. Let's try __exhaustive feature selection__ instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d382d6-6f04-4140-9352-0776d5cd989d",
   "metadata": {},
   "source": [
    "## Using exhaustive feature selection\n",
    "\n",
    "> Note, we are skipping this because this might not be practical in production. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226b45d-2d93-43e0-b247-c482dc42eedb",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Wrapper methods, such as forward, backward and exhaustive feature selection, tax system resources because they need to be trained with each iteration, and the more difficult the choosen algorithm is to implement, the more this is an issue.\n",
    "\n",
    "\n",
    "__Recursive feature elimination (RFE)__ is something of a compromise between the simplicity of filter methods and the better information provided by wrapper methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40041d-5372-4454-af2b-fdfff2faea1c",
   "metadata": {},
   "source": [
    "## Eliminating features recursively in a regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ae5bd-9aa5-4ff0-8ef2-1d210c753dd5",
   "metadata": {},
   "source": [
    "A popular wrapper method is RFE. This method starts with all features, removes the lowest weighted one (based on a coefficient or feature importance measure), and repeats the process until the best-fitting model has been identified. When a feature is removed, it is given a ranking reflecting the point at which it was removed.\n",
    "\n",
    "RFE can be used for both regression models and classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46569213-5687-43ff-b95a-c20bf6b48d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from data.load import load_nls97wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6808fb1-e561-4b82-bc58-df8915040c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nls97wages = load_nls97wages()\n",
    "feature_cols = [\n",
    "    \"satverbal\",\n",
    "    \"satmath\",\n",
    "    \"gpascience\",\n",
    "    \"gpaenglish\",\n",
    "    \"gpamath\",\n",
    "    \"gpaoverall\",\n",
    "    \"motherhighgrade\",\n",
    "    \"fatherhighgrade\",\n",
    "    \"parentincome\",\n",
    "    \"gender\",\n",
    "    \"completedba\",\n",
    "]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    nls97wages[feature_cols], nls97wages[[\"weeklywage\"]], test_size=0.3, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5ece436-e925-455a-a1ca-0e45b430edfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_cols = list(X_train.columns)\n",
    "num_cols.remove(\"gender\")\n",
    "cat_cols = [\"gender\"]\n",
    "\n",
    "cat_transformer = make_pipeline(OneHotEncoder(drop=\"first\"))\n",
    "num_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat_cols\", cat_transformer, cat_cols),\n",
    "        (\"num_cols\", num_transformer, num_cols),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "X_train_enc = pd.DataFrame(\n",
    "    transformer.fit_transform(X_train),\n",
    "    columns=transformer.get_feature_names_out(),\n",
    "    index=X_train.index,\n",
    ")\n",
    "X_test_enc = pd.DataFrame(\n",
    "    transformer.fit_transform(X_test),\n",
    "    columns=transformer.get_feature_names_out(),\n",
    "    index=X_test.index,\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "y_train = pd.DataFrame(\n",
    "    scaler.fit_transform(y_train), columns=[\"weeklywage\"], index=y_train.index\n",
    ")\n",
    "y_test = pd.DataFrame(\n",
    "    scaler.fit_transform(y_test), columns=[\"weeklywage\"], index=y_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25510d52-0527-4109-b7ba-100baa4c172d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Since RFE is a wrapper method, we need to choose an algorithm around which the selection will be wrapped. Random forests for regression make sense in this case. We are modelling a continuous target and do not want to assume a linear relationship between the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d2aa57b-d7d7-4527-838c-2028d0ae9338",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satmath', 'gpascience', 'gpaoverall', 'parentincome', 'completedba'], dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We set max_depth to 2 to avoid overfitting.\n",
    "rfr = RandomForestRegressor(max_depth=2)\n",
    "tree_sel = RFE(estimator=rfr, n_features_to_select=5)\n",
    "tree_sel.fit(X_train_enc, y_train.values.ravel())\n",
    "sel_cols = X_train_enc.columns[tree_sel.get_support()]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99979320-41e6-4a91-bf5f-c61855954de9",
   "metadata": {},
   "source": [
    "We can use the `ranking_` attribute to see when each of the eliminated features was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "053da5d0-9b51-4f16-a7f1-54be2afdcc9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>satmath</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpascience</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpaoverall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>parentincome</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>completedba</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender_Male</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>motherhighgrade</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fatherhighgrade</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satverbal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpaenglish</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpamath</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  ranking\n",
       "2           satmath        1\n",
       "3        gpascience        1\n",
       "6        gpaoverall        1\n",
       "9      parentincome        1\n",
       "10      completedba        1\n",
       "0       gender_Male        2\n",
       "7   motherhighgrade        3\n",
       "8   fatherhighgrade        4\n",
       "1         satverbal        5\n",
       "4        gpaenglish        6\n",
       "5           gpamath        7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"ranking\": tree_sel.ranking_,\n",
    "        \"feature\": X_train_enc.columns,\n",
    "    },\n",
    "    columns=[\"feature\", \"ranking\"],\n",
    ").sort_values([\"ranking\"], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e296da-16de-4c2c-8b51-34219c5f4f20",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can use the `score` method to get the __r-squared value__, also known as the coefficient of determination. __R-squared__ is a measure of the percentage of total variation explained by our model. We get a very low score, indicating that our model explains only a little of the variation.\n",
    "\n",
    "See `rfr.score?` for detailed explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "331512ba-6b03-4e75-940b-a0a2238e8856",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11476590269688303"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(tree_sel.transform(X_train_enc), y_train.values.ravel())\n",
    "rfr.score(tree_sel.transform(X_test_enc), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f3af50-ce94-4046-9440-857768e71637",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's see whether we get any better results using RFE with a linear regression model. This model returns the same features as the random forest regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a513ebe9-6257-460c-8199-a11917c521fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satmath', 'gpascience', 'gpaoverall', 'parentincome', 'completedba'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr_sel = RFE(estimator=lr, n_features_to_select=5)\n",
    "lr_sel.fit(X_train_enc, y_train.values.ravel())\n",
    "sel_cols = X_train_enc.columns[tree_sel.get_support()]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36098ed8-df66-449b-8835-29020b7fb440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17393446569288262"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(lr_sel.transform(X_train_enc), y_train.values.ravel())\n",
    "lr.score(lr_sel.transform(X_test_enc), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7756745-3dd9-4559-a25d-90e4247a0cd1",
   "metadata": {},
   "source": [
    "^ The linear model is not really much better than the random forest model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c980d1e5-8f97-44ff-9e14-178ed2a52b1a",
   "metadata": {},
   "source": [
    "## Eliminating features recursively in a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5875e7a3-b9bd-45ba-8fb4-749a12fd549c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from data.load import load_nls97compba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc75f98a-7ab1-4f10-b988-73de9316c305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nls97compba = load_nls97compba()\n",
    "feature_cols = [\n",
    "    \"satverbal\",\n",
    "    \"satmath\",\n",
    "    \"gpascience\",\n",
    "    \"gpaenglish\",\n",
    "    \"gpamath\",\n",
    "    \"gpaoverall\",\n",
    "    \"gender\",\n",
    "    \"motherhighgrade\",\n",
    "    \"fatherhighgrade\",\n",
    "    \"parentincome\",\n",
    "]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    nls97compba[feature_cols],\n",
    "    nls97compba[[\"completedba\"]],\n",
    "    test_size=0.3,\n",
    "    random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "024bf6b7-3d2c-4288-8126-98f5b97bd7dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_cols = feature_cols[:]\n",
    "num_cols.remove(\"gender\")\n",
    "cat_cols = [\"gender\"]\n",
    "\n",
    "num_transformer = make_pipeline(StandardScaler())\n",
    "cat_transformer = make_pipeline(OneHotEncoder(drop=\"first\"))\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    [(\"num_cols\", num_transformer, num_cols), (\"cat_cols\", cat_transformer, cat_cols)],\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "X_train_enc = pd.DataFrame(\n",
    "    transformer.fit_transform(X_train),\n",
    "    columns=transformer.get_feature_names_out(),\n",
    "    index=X_train.index,\n",
    ")\n",
    "X_test_enc = pd.DataFrame(\n",
    "    transformer.fit_transform(X_test),\n",
    "    columns=transformer.get_feature_names_out(),\n",
    "    index=X_test.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "903a0010-2b3a-4853-a1df-f515a077eaaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satverbal', 'satmath', 'gpascience', 'gpaenglish', 'gpaoverall'], dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1, random_state=0)\n",
    "tree_sel = RFE(estimator=rfc, n_features_to_select=5)\n",
    "tree_sel.fit(X_train_enc, y_train.values.ravel())\n",
    "sel_cols = X_train_enc.columns[tree_sel.get_support()]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f1399a3-1fb6-46b0-bfe3-6a7d09048b69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satverbal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satmath</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpascience</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpaenglish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpaoverall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpamath</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>parentincome</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fatherhighgrade</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>motherhighgrade</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gender_Male</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  ranking\n",
       "0        satverbal        1\n",
       "1          satmath        1\n",
       "2       gpascience        1\n",
       "3       gpaenglish        1\n",
       "5       gpaoverall        1\n",
       "4          gpamath        2\n",
       "8     parentincome        3\n",
       "7  fatherhighgrade        4\n",
       "6  motherhighgrade        5\n",
       "9      gender_Male        6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": X_train_enc.columns,\n",
    "        \"ranking\": tree_sel.ranking_,\n",
    "    },\n",
    "    columns=[\"feature\", \"ranking\"],\n",
    ").sort_values([\"ranking\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac24510d-9fa7-4994-a6cc-a92c3dfbf401",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(tree_sel.transform(X_train_enc), y_train.values.ravel())\n",
    "y_pred = rfc.predict(tree_sel.transform(X_test_enc))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d2c92-8af7-4d04-8948-3b6840eb3c61",
   "metadata": {},
   "source": [
    "## Using regularization and other embedded methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05b59e-2125-405d-b0a2-5d0a7efe4f35",
   "metadata": {},
   "source": [
    "__Regularization__ methods are embedded methods. Like _wrapper methods_, embedded methods evaluate features relative to a given algorithm. But they are not expensive computationally.\n",
    "\n",
    "Embedded models use the following process:\n",
    "1. Train a model\n",
    "2. Estimate each feature's importance to the model's prediction\n",
    "3. Remove features with low importance\n",
    "\n",
    "Regularization accomplishes this by adding a penalty to any model to constrain the parameters. __L1 regularization__, also referred to as __lasso regularization__, shrinks some of the coefficients in a regression model to 0, effectively eliminating those features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe3af5-2bf2-42ba-9ecf-1af9163d79c5",
   "metadata": {},
   "source": [
    "### Using L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7be11d3-bfb7-4847-96e8-842f3df78888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from data.load import load_nls97compba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b61349e-e22f-4888-94c7-bf5b1eebd57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nls97compba = load_nls97compba()\n",
    "feature_cols = [\n",
    "    \"satverbal\",\n",
    "    \"satmath\",\n",
    "    \"gpascience\",\n",
    "    \"gpaenglish\",\n",
    "    \"gpamath\",\n",
    "    \"gpaoverall\",\n",
    "    \"gender\",\n",
    "    \"motherhighgrade\",\n",
    "    \"fatherhighgrade\",\n",
    "    \"parentincome\",\n",
    "]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    nls97compba[feature_cols],\n",
    "    nls97compba[[\"completedba\"]],\n",
    "    test_size=0.3,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "\n",
    "cat_cols = [\"gender\"]\n",
    "num_cols = feature_cols[:]\n",
    "num_cols.remove(\"gender\")\n",
    "\n",
    "cat_transformer = make_pipeline(OneHotEncoder(drop=\"first\"))\n",
    "num_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", num_transformer, num_cols),\n",
    "        (\"cat\", cat_transformer, cat_cols),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "X_train_enc = pd.DataFrame(\n",
    "    transformer.fit_transform(X_train),\n",
    "    columns=transformer.get_feature_names_out(),\n",
    "    index=X_train.index,\n",
    ")\n",
    "X_test_enc = pd.DataFrame(\n",
    "    transformer.fit_transform(X_test),\n",
    "    columns=transformer.get_feature_names_out(),\n",
    "    index=X_test.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346ad151-1fa5-4330-950f-355078577b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satmath', 'gpascience', 'gpaoverall', 'fatherhighgrade',\n",
       "       'gender_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1, penalty=\"l1\", solver=\"liblinear\")\n",
    "reg_sel = SelectFromModel(lr, max_features=5)\n",
    "reg_sel.fit(X_train_enc, y_train.values.ravel())\n",
    "sel_cols = X_train_enc.columns[reg_sel.get_support()]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23ecc07-abd8-4e2f-be6a-b1cd4da9194f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6886446886446886"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(reg_sel.transform(X_train_enc), y_train.values.ravel())\n",
    "y_pred = lr.predict(reg_sel.transform(X_test_enc))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10aa4b-e5cc-4731-a97a-07ee2715380b",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Lasso regularization assumes a linear relationship between the features and the target, which might not be appropriate. Fortunately, there are embedded feature selection methods that do not make that assumption. A good alternative to logistic regression for the embedded model is a random forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e49d4da-51a3-4146-b56f-be5c01bc0ee4",
   "metadata": {},
   "source": [
    "### Using a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f918659a-9a74-445a-82c8-3bf35b641b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satverbal', 'gpascience', 'gpaenglish', 'gpaoverall'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1, random_state=0)\n",
    "rfc_sel = SelectFromModel(rfc, max_features=5)\n",
    "rfc_sel.fit(X_train_enc, y_train.values.ravel())\n",
    "sel_cols = X_train_enc.columns[rfc_sel.get_support()]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c359f4-3c5e-43ef-beff-3efd4d0aae00",
   "metadata": {},
   "source": [
    "^ This actually selects very different features from the lasso regression. `satmath`, `fatherhighgrade` and `gender_Male` are no longer selected, while `satverbal` and `gpaenglish` are. This is likely due to the relaxation of the assumption of linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b6bde0c-aa7c-47ba-b04a-838f1b94b965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6703296703296703"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(rfc_sel.transform(X_train_enc), y_train.values.ravel())\n",
    "y_pred = rfc.predict(rfc_sel.transform(X_test_enc))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb78899-718c-4446-b9d6-031e7aceffac",
   "metadata": {},
   "source": [
    "## Using principal component analysis\n",
    "\n",
    "PCA allows us to replace the existing feature set with a limited number of components, each of which explains an important amount of the variance. It does this by finding a component that captures the largest amount of variance, followed by a second component that captures the largest amount of remaining variance, and then a third component, and so on. \n",
    "\n",
    "One key advantage of this approach is that these components, known as __principal components__, are uncorrelated.\n",
    "\n",
    "It is better to think of PCA as a tool for dimension reduction rather than feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9da3bb3-1208-429c-975e-4bf66019147e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f20c8ca-eb08-4bc9-b6e3-424aad48a66f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca.fit(X_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda5dd9-00b1-4924-a4e1-16791a126807",
   "metadata": {},
   "source": [
    "The `components_` attribute of PCA object returns the scores of all 10 features on each of the 5 components. The features that drive the first component most are those with scores that have the highest absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8de9dcc-36de-4e0e-8f53-ba9c3daa16f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>satverbal</th>\n",
       "      <td>-0.344599</td>\n",
       "      <td>-0.155500</td>\n",
       "      <td>-0.609857</td>\n",
       "      <td>-0.015720</td>\n",
       "      <td>-0.194730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satmath</th>\n",
       "      <td>-0.365310</td>\n",
       "      <td>-0.133004</td>\n",
       "      <td>-0.560769</td>\n",
       "      <td>0.101711</td>\n",
       "      <td>0.108085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpascience</th>\n",
       "      <td>-0.399085</td>\n",
       "      <td>0.213678</td>\n",
       "      <td>0.181046</td>\n",
       "      <td>0.025388</td>\n",
       "      <td>0.024021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpaenglish</th>\n",
       "      <td>-0.402801</td>\n",
       "      <td>0.218715</td>\n",
       "      <td>0.181740</td>\n",
       "      <td>-0.083811</td>\n",
       "      <td>-0.186303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpamath</th>\n",
       "      <td>-0.379170</td>\n",
       "      <td>0.243580</td>\n",
       "      <td>0.116025</td>\n",
       "      <td>0.077460</td>\n",
       "      <td>0.234863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpaoverall</th>\n",
       "      <td>-0.425672</td>\n",
       "      <td>0.251455</td>\n",
       "      <td>0.229665</td>\n",
       "      <td>-0.043660</td>\n",
       "      <td>-0.034032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motherhighgrade</th>\n",
       "      <td>-0.185914</td>\n",
       "      <td>-0.514389</td>\n",
       "      <td>0.239725</td>\n",
       "      <td>-0.428150</td>\n",
       "      <td>-0.588300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatherhighgrade</th>\n",
       "      <td>-0.201618</td>\n",
       "      <td>-0.507950</td>\n",
       "      <td>0.179787</td>\n",
       "      <td>-0.346770</td>\n",
       "      <td>0.703983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentincome</th>\n",
       "      <td>-0.160537</td>\n",
       "      <td>-0.461227</td>\n",
       "      <td>0.279373</td>\n",
       "      <td>0.817850</td>\n",
       "      <td>-0.075447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_Male</th>\n",
       "      <td>0.018166</td>\n",
       "      <td>-0.082061</td>\n",
       "      <td>-0.117291</td>\n",
       "      <td>0.037323</td>\n",
       "      <td>0.106830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4\n",
       "satverbal       -0.344599 -0.155500 -0.609857 -0.015720 -0.194730\n",
       "satmath         -0.365310 -0.133004 -0.560769  0.101711  0.108085\n",
       "gpascience      -0.399085  0.213678  0.181046  0.025388  0.024021\n",
       "gpaenglish      -0.402801  0.218715  0.181740 -0.083811 -0.186303\n",
       "gpamath         -0.379170  0.243580  0.116025  0.077460  0.234863\n",
       "gpaoverall      -0.425672  0.251455  0.229665 -0.043660 -0.034032\n",
       "motherhighgrade -0.185914 -0.514389  0.239725 -0.428150 -0.588300\n",
       "fatherhighgrade -0.201618 -0.507950  0.179787 -0.346770  0.703983\n",
       "parentincome    -0.160537 -0.461227  0.279373  0.817850 -0.075447\n",
       "gender_Male      0.018166 -0.082061 -0.117291  0.037323  0.106830"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components_df = pd.DataFrame(pca.components_, columns=X_train_enc.columns).T\n",
    "components_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9dc5d63-42b8-4820-8f7e-b62e86a98c28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component #0:\n",
      "gpaoverall    0.425672\n",
      "gpaenglish    0.402801\n",
      "gpascience    0.399085\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "component #1:\n",
      "motherhighgrade    0.514389\n",
      "fatherhighgrade    0.507950\n",
      "parentincome       0.461227\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "component #2:\n",
      "satverbal       0.609857\n",
      "satmath         0.560769\n",
      "parentincome    0.279373\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "component #3:\n",
      "parentincome       0.81785\n",
      "motherhighgrade    0.42815\n",
      "fatherhighgrade    0.34677\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "component #4:\n",
      "fatherhighgrade    0.703983\n",
      "motherhighgrade    0.588300\n",
      "gpamath            0.234863\n",
      "Name: 4, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The features that drives each components.\n",
    "for i in range(5):\n",
    "    print(f\"component #{i}:\")\n",
    "    print(components_df.iloc[:, i].map(abs).sort_values(ascending=False).head(3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93895048-6c7e-4c30-9216-ad3cef1e778d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46073387, 0.19036089, 0.09295703, 0.07163009, 0.05328056])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac272c2-f19a-4bc3-b5b3-e67d2403b6eb",
   "metadata": {},
   "source": [
    "^ The first component accounts for 46% of the variance alone, followed by an additional 19% for the second component. We can use NumPy's `cumsum` method to see how much of feature variance is explained by the five components cumulatively. We can explain 87% of the variance in the 10 features with 5 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ab6a7b6-3088-4774-9f1e-04f3524371b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46073387, 0.65109476, 0.74405179, 0.81568188, 0.86896244])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20540c33-5408-47a8-b9f1-3d6de8f64ed9",
   "metadata": {},
   "source": [
    "Let's transform our features in the testing data based on these five principal compnents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7485c4fe-0a8b-4c71-80b8-bbbfae395e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634, 5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca = pca.transform(X_train_enc)\n",
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43b41002-4b29-4204-834a-23e1029e57f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7032967032967034"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca = pca.transform(X_test_enc)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1, random_state=0)\n",
    "rfc.fit(X_train_pca, y_train.values.ravel())\n",
    "\n",
    "y_pred = rfc.predict(X_test_pca)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b92fa8-7f72-4f02-a35e-79e3fc21fb0c",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "A dimension reduction technique such as PCA can be a good option when the feature selection challenge is that we have highly correlated features and we want to reduce the number of dimensions without substantially reducting the explained variance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
